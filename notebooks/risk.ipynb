{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "from itertools import product\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import gaussian_kde, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### Volatility\n",
    "\n",
    "In finance, volatility refers to a measure of deviation from an expectation, typically in the context of the return space - not the price path space\n",
    "\n",
    "Since volatility requires deviation from some sort of expectation, a mean level is required for reference\n",
    "\n",
    "In other words, we think of this expectation as a benchmark \"this is volatility relative to some expectation\"\n",
    "\n",
    "  Expected returns (forward looking): \n",
    "  \n",
    "  $$\\mathbb{E}[R_t] = \\mu_t$$\n",
    "  \n",
    "  Variance of returns (forward looking):\n",
    "  $$\\text{Var}(R_t) = \\mathbb{E}[(R_t - \\mu_t)^2] = \\sigma_t^2$$\n",
    "  \n",
    "  Note: $\\mu_t$ is not directly observable and likely changes over time. This makes it difficult to get accurate \n",
    "  estimates of expected returns. Since variance depends on deviations from $\\mu_t$, this uncertainty in the mean\n",
    "  also impacts our ability to measure volatility accurately.\n",
    "\n",
    "  **Remark:** Here we are talking about a return based on some risk exposure, not some sort of statistical mispricing which would change this analysis entirely.\n",
    "  \n",
    "Neither is **directly** observable\n",
    "\n",
    "- we can proxy forward looking returns using historical returns\n",
    "\n",
    "- we can proxy forward looking volatility using realized/historic volatility or implied volatility\n",
    "\n",
    "But the spot estimates in a forward looking sense depend on a time interval (forward looking returns) and current market state (forward implied vol)\n",
    "\n",
    "Nothing says the market has to play out according to these spot estimations. . .\n",
    "\n",
    "##### Realized or Historic Volatility\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the volatility data\n",
    "stock = \"BTCUSDT\"\n",
    "df = pd.read_csv(f\"../data/{stock}.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"open_time\"])\n",
    "df.drop([\"open_time\"], axis=1, inplace=True)\n",
    "\n",
    "# Calculate annualized squared deviations from rolling means\n",
    "df[\"returns\"] = df[\"close\"].pct_change()\n",
    "df[\"sq_dev_7d\"] = (df[\"returns\"] - df[\"returns\"].rolling(7).mean()) ** 2 * 252\n",
    "df[\"sq_dev_30d\"] = (df[\"returns\"] - df[\"returns\"].rolling(30).mean()) ** 2 * 252\n",
    "\n",
    "# Cut off first 30 days\n",
    "df = df[30:]\n",
    "\n",
    "# Create subplots - 1 row, 2 columns\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(f\"{stock} Returns\", \"Volatility Measures\"),\n",
    "    horizontal_spacing=0.1,\n",
    ")\n",
    "\n",
    "# Plot returns\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"date\"],\n",
    "        y=df[\"returns\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Returns\",\n",
    "        line=dict(color=\"#FF00FF\", width=1.5),  # Neon pink\n",
    "        showlegend=True,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"date\"],\n",
    "        y=np.sqrt(df[\"sq_dev_7d\"].rolling(7).mean()),\n",
    "        mode=\"lines\",\n",
    "        name=\"7-day Rolling Vol\",\n",
    "        line=dict(color=\"#FF3131\", width=1.5),  # Neon red\n",
    "        showlegend=True,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"date\"],\n",
    "        y=np.sqrt(df[\"sq_dev_30d\"].rolling(30).mean()),\n",
    "        mode=\"lines\",\n",
    "        name=\"30-day Rolling Vol\",\n",
    "        line=dict(color=\"#00FFFF\", width=1.5),  # Neon cyan\n",
    "        showlegend=True,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "for col in [1, 2]:\n",
    "    fig.update_xaxes(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "        title_text=\"Date\",\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "        title_text=\"Returns\" if col == 1 else \"Volatility\",\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "##### Implied Volatility\n",
    "\n",
    "The Black-Scholes model gives us a forward looking measure of volatility called implied volatility\n",
    "\n",
    "Essentially, volatility is an input into an option's price and we can use market prices (generated by supply and demand) to produce this value\n",
    "\n",
    " The implied volatility $\\sigma_{IV}$ is found by solving:\n",
    "  The Black-Scholes PDE:\n",
    "  \n",
    "  $$\\frac{\\partial C}{\\partial t} + \\frac{1}{2}\\sigma^2S^2\\frac{\\partial^2 C}{\\partial S^2} + rS\\frac{\\partial C}{\\partial S} - rC = 0$$\n",
    "  \n",
    "  With solution for a European call option:\n",
    "  \n",
    "  $$C_{BS}(S,K,r,T,\\sigma) = SN(d_1) - Ke^{-rT}N(d_2)$$\n",
    "  \n",
    "  where $d_1 = \\frac{\\ln(S/K) + (r + \\sigma^2/2)T}{\\sigma\\sqrt{T}}$ and $d_2 = d_1 - \\sigma\\sqrt{T}$\n",
    "  \n",
    "  The implied volatility $\\sigma_{IV}$ is then found by solving:\n",
    "  \n",
    "  $$\\sigma_{IV} = \\underset{\\sigma}{\\text{argmin}} \\left| C_{market} - C_{BS}(S, K, r, T, \\sigma) \\right|$$\n",
    " \n",
    " where $C_{market}$ is the market price of the option and $C_{BS}$ is the Black-Scholes price\n",
    "\n",
    "\n",
    "This gives us a sense of what level of volatility traders are pricing options expiring in the future at\n",
    "\n",
    "It is effectively a best guess at the volatility in a forward looking sense with *money on the line* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "**Note:** We can always apply time series techniques (smoothing, filtering, forecasting) to any measure of volatility (historic or implied) but the efficacy of such an approach is problem dependent!  As observed above the correlation between historic (30-day realized vol) and implied volatility varies significantly over time - there are several reasons why this is the case which we will look at. . .\n",
    "\n",
    "Primarily, implied volatility is a *forward* looking measure and realized is a *backward* looking measure, correlations between these structures depend on time and the regime of volatility and if it is increasing or decreasing which will then cause these measures to become more or less correlated. . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "A well documented phenomenon is the notion of volatility realizing *lower* than implied volatility would suggest\n",
    "\n",
    "Many volatility trading strategies involve this idea, for example, holding net negative vega exposure while delta hedging directional risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "##### Relevant Statistics\n",
    "\n",
    "A feature we observe in returns is this idea of *excess kurtosis* or \"fat tails\" which is defined as leptokurtosis or a leptokurtic return distribution.\n",
    "\n",
    "Formally, Kurtosis is the 4th statistical moment\n",
    " For a random variable X, kurtosis can be derived from the moment generating function (MGF):\n",
    " \n",
    " $$M_X(t) = E[e^{tX}]$$\n",
    " \n",
    " The kurtosis is then:\n",
    " \n",
    " $$Kurt[X] = \\frac{M_X^{(4)}(0)}{(M_X^{(2)}(0))^2}$$\n",
    " \n",
    " For a Normal distribution with mean $\\mu$ and variance $\\sigma^2$, the MGF is:\n",
    " \n",
    " $$M_X(t) = e^{\\mu t + \\frac{\\sigma^2t^2}{2}}$$\n",
    " \n",
    " Taking derivatives and evaluating at t=0:\n",
    " \n",
    " $$M_X^{(4)}(0) = 3\\sigma^4$$\n",
    " $$M_X^{(2)}(0) = \\sigma^2$$\n",
    " \n",
    " Therefore:\n",
    " \n",
    " $$Kurt[X] = \\frac{3\\sigma^4}{(\\sigma^2)^2} = 3$$\n",
    " \n",
    " This shows that a Normal distribution always has kurtosis = 3, while empirical returns typically have kurtosis > 3 (leptokurtic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns distribution statistics\n",
    "returns_mean = df[\"returns\"].mean()\n",
    "returns_std = df[\"returns\"].std()\n",
    "returns_kurt = (\n",
    "    df[\"returns\"].kurtosis() + 3\n",
    ")  # Convert from excess kurtosis to regular kurtosis\n",
    "\n",
    "# Generate normal distribution with same mean and std\n",
    "normal_dist = np.random.normal(returns_mean, returns_std, 100000)\n",
    "normal_kurt = 3  # Normal distribution has kurtosis of 3\n",
    "\n",
    "# Create KDE plots\n",
    "kde_returns = gaussian_kde(df[\"returns\"])\n",
    "kde_normal = gaussian_kde(normal_dist)\n",
    "\n",
    "# Create evaluation points\n",
    "x_range = np.linspace(\n",
    "    min(df[\"returns\"].min(), normal_dist.min()),\n",
    "    max(df[\"returns\"].max(), normal_dist.max()),\n",
    "    1000,\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add returns KDE\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_range,\n",
    "        y=kde_returns(x_range),\n",
    "        name=\"Returns Distribution\",\n",
    "        line=dict(color=\"#39FF14\", width=2),\n",
    "        mode=\"lines\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add normal KDE\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_range,\n",
    "        y=kde_normal(x_range),\n",
    "        name=\"Normal Distribution\",\n",
    "        line=dict(color=\"#FF10F0\", width=2),\n",
    "        mode=\"lines\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    title=f\"Returns Distribution vs Normal<br>Returns Kurtosis: {returns_kurt:.2f}, Normal Kurtosis: {normal_kurt:.2f}\",\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Returns\",\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Density\",\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "##### Stylized Facts of Volatility\n",
    "\n",
    "1. Volatility Clustering: Periods of high volatility tend to cluster together, and periods of low volatility tend to cluster together. This means volatility shows persistence and autocorrelation.\n",
    "\n",
    "2. Mean Reversion: While volatility clusters, it tends to revert back to a long-run average level over time. Extremely high or low volatility periods don't persist indefinitely.\n",
    "\n",
    "3. Leverage Effect: Volatility tends to increase more after negative returns compared to positive returns of the same magnitude. This creates an asymmetric response.\n",
    "\n",
    "4. Heavy Tails: Returns distributions show excess kurtosis (fat tails) compared to normal distribution, indicating more extreme events than expected.\n",
    "\n",
    "5. Long Memory: Volatility shows long-range dependence, meaning past volatility can influence future volatility even after significant time lags. (some evidence that rough volatility models and fractional Brownian motions can capture this, other literature suggests the evidence is ill founded. . .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots to show stylized facts\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Volatility Mean Reversion\", \"Leverage Effect\"),\n",
    "    horizontal_spacing=0.1,\n",
    ")\n",
    "\n",
    "# Plot 1: Volatility Mean Reversion\n",
    "rolling_vol = df[\"returns\"].rolling(window=20).std() * np.sqrt(252)\n",
    "long_term_vol = rolling_vol.mean()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df.index,\n",
    "        y=rolling_vol,\n",
    "        mode=\"lines\",\n",
    "        name=\"20-day Rolling Volatility\",\n",
    "        line=dict(color=\"#00FFFF\", width=1.5),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=long_term_vol,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"Long-term Average\",\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Plot 2: Leverage Effect\n",
    "returns_lag = df[\"returns\"].shift(1)\n",
    "vol_change = rolling_vol.diff()\n",
    "\n",
    "neg_returns = returns_lag[returns_lag < 0]\n",
    "pos_returns = returns_lag[returns_lag > 0]\n",
    "neg_vol_change = vol_change[returns_lag < 0]\n",
    "pos_vol_change = vol_change[returns_lag > 0]\n",
    "\n",
    "# Calculate average vol changes\n",
    "avg_neg_change = neg_vol_change.mean()\n",
    "avg_pos_change = pos_vol_change.mean()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=neg_returns,\n",
    "        y=neg_vol_change,\n",
    "        mode=\"markers\",\n",
    "        name=f\"After Negative Returns (avg: {avg_neg_change:.4f})\",\n",
    "        marker=dict(color=\"#FF10F0\", size=6, opacity=0.6),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pos_returns,\n",
    "        y=pos_vol_change,\n",
    "        mode=\"markers\",\n",
    "        name=f\"After Positive Returns (avg: {avg_pos_change:.4f})\",\n",
    "        marker=dict(color=\"#39FF14\", size=6, opacity=0.6),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=600,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\", size=12),\n",
    ")\n",
    "\n",
    "# Update axes styling for all subplots\n",
    "for i in range(1, 2):\n",
    "    for j in range(1, 3):\n",
    "        fig.update_xaxes(\n",
    "            showgrid=True,\n",
    "            gridwidth=1,\n",
    "            gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "            zeroline=True,\n",
    "            zerolinewidth=1.5,\n",
    "            zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "            row=i,\n",
    "            col=j,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            showgrid=True,\n",
    "            gridwidth=1,\n",
    "            gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "            zeroline=True,\n",
    "            zerolinewidth=1.5,\n",
    "            zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "            row=i,\n",
    "            col=j,\n",
    "        )\n",
    "\n",
    "# Add specific axis labels\n",
    "fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Previous Return\", row=1, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Volatility\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Volatility Change\", row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "**Remark:** Clearly, all of these dynamics are important to capture in our model otherwise our estimates may be extremely far from reality.  Prior to Engle and ARCH, models were unable to capture these stylized facts of volatility, heteroskedasticity, and excess kurtosis in one parsimonious model - sure there were ways to capture it, but there is always a complexity/efficiency tradeoff. . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### ARCH Models (Engle 1982)\n",
    "\n",
    "##### *\"Autoregressive Conditionally Heteroskedastic Models\"*\n",
    "\n",
    "##### ARCH(q) Models\n",
    "\n",
    "$$y_t = \\mu + \\epsilon_t \\quad \\epsilon_t = \\sigma_t z_t \\quad z_t \\sim i.i.d (0, 1)$$\n",
    "\n",
    "- $y_t$ is the observed time series (e.g., returns at time t; we don't use price here as $y_t$ is defined as stationary in expectation in terms of $\\mu$)\n",
    "- $\\mu$ is the constant mean of the process $y_t$, something like the mean return (typically *about zero*)\n",
    "- $\\epsilon_t$ is the rror term (shock, innovation, residual) at time t\n",
    "- $z_t$ is an i.i.d random variable with mean 0 and variance 1 (often assumed $\\sim N(0, 1)$ but other heavy tailed distributions are also relevant)\n",
    "\n",
    "$$\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\alpha_2 \\epsilon_{t-2}^2 + . . . + \\alpha_q \\epsilon_{t-q}^2$$\n",
    "- $\\sigma^t_t$ is the conditional variance of $\\epsilon_t$ or the *volatility* given past information dictated by the order of the ARCH process\n",
    "- $\\alpha_0$ is the constant term in the variance equation and must be positive to ensure nonzero variance\n",
    "- $\\alpha_i$ is the coefficient on lagged squared residuals ($\\epsilon_{t-i}^2$) and must also be nonnegative to ensure nonnegative variance\n",
    "\n",
    "\n",
    "**Autoregressive :** Uses a linear combination of its own past values to estimate future states\n",
    "\n",
    "**Heteroskedastic vs. Homoskedastic:** If a model is homoskedastic it proposes constant variance (volatility) which is not the case as observed in data! where if a model is heteroskedastic it propses variance (volatility) is not constant - more inline with what we observe in data!\n",
    "\n",
    "**Conditionally Heteroskedastic:** Variance of errors in a model changes over time and is dependent on past information - quite useful here for volatility!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "##### Previous Models Failed to Capture the Dynamics Discussed Above\n",
    "\n",
    " *Historical volatility:* Simple rolling window standard deviation of returns\n",
    "\n",
    " *Exponential weighted moving average (EWMA):* Gives more weight to recent observations\n",
    "\n",
    " *Implied volatility:* Derived from option prices using Black-Scholes model\n",
    "\n",
    " *Stochastic volatility models:* Allow volatility to follow its own random process\n",
    " \n",
    " These models had limitations:\n",
    "   - Could not capture volatility clustering well\n",
    "   - Did not model the relationship between returns and volatility\n",
    "   - Often assumed constant parameters over time\n",
    "\n",
    "How can we compare the efficacy of these models?  We can benchmark against realized volatility in a forward looking sense!\n",
    "\n",
    "We give the model data up to time $t-1$ and use it to try to forecast volatility at time $t$ and see which does better on average!\n",
    "\n",
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Example: EWMA vs. ARCH(1)\n",
    "\n",
    "**Remark:** There is a slight bias, even out of sample, through grid search with window size as this is acting on global path knowledge, but sufficient for our analysis as we apply the same methodology to produce OOS statistics for each technique. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "realized_var = (df[\"returns\"] ** 2) * 252\n",
    "\n",
    "# -----------------------\n",
    "# Train/Test Split\n",
    "# -----------------------\n",
    "train_end_idx = int(len(df) * 0.7)  # 70% training\n",
    "train_data = df.iloc[:train_end_idx]\n",
    "test_data = df.iloc[train_end_idx:]\n",
    "train_end = train_data.index[-1]\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# EWMA Forecast Function\n",
    "# -----------------------\n",
    "def ewma_forecast(returns, lam):\n",
    "    ewma_var = np.zeros(len(returns))\n",
    "    ewma_var[0] = returns.var()  # initialize with unconditional variance\n",
    "    for t in range(1, len(returns)):\n",
    "        ewma_var[t] = lam * ewma_var[t - 1] + (1 - lam) * returns.iloc[t - 1] ** 2\n",
    "    return ewma_var * 252  # annualize\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Grid Search for Optimal λ (train set only)\n",
    "# -----------------------\n",
    "lambda_grid = np.linspace(0.01, 0.90, 100)\n",
    "best_rmse = float(\"inf\")\n",
    "best_lambda = None\n",
    "\n",
    "for lam in lambda_grid:\n",
    "    ewma_train = ewma_forecast(train_data[\"returns\"], lam)\n",
    "    rmse = np.sqrt(((ewma_train - realized_var[train_data.index]) ** 2).mean())\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_lambda = lam\n",
    "\n",
    "print(f\"Best λ found: {best_lambda:.3f} (Train RMSE={best_rmse:.6f})\")\n",
    "\n",
    "# -----------------------\n",
    "# Out-of-Sample Forecast using Best λ\n",
    "# -----------------------\n",
    "ewma_all = ewma_forecast(df[\"returns\"], best_lambda)\n",
    "ewma_forecast_var = pd.Series(ewma_all, index=df.index)\n",
    "\n",
    "aligned = pd.DataFrame({\"realized_var\": realized_var, \"ewma_var\": ewma_forecast_var})\n",
    "\n",
    "# OOS performance\n",
    "oos_data = aligned[train_end:]\n",
    "mse = ((oos_data[\"ewma_var\"] - oos_data[\"realized_var\"]) ** 2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "mae = (oos_data[\"ewma_var\"] - oos_data[\"realized_var\"]).abs().mean()\n",
    "\n",
    "X = sm.add_constant(oos_data[\"ewma_var\"])\n",
    "y = oos_data[\"realized_var\"]\n",
    "model = sm.OLS(y, X).fit()\n",
    "r2 = model.rsquared\n",
    "\n",
    "# -----------------------\n",
    "# Visualization\n",
    "# -----------------------\n",
    "fig = go.Figure()\n",
    "\n",
    "# Realized variance\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=aligned.index,\n",
    "        y=aligned[\"realized_var\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Realized Variance (Daily)\",\n",
    "        line=dict(color=\"#BC13FE\", width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "# EWMA variance forecast\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=aligned.index,\n",
    "        y=aligned[\"ewma_var\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"EWMA Forecast (λ={best_lambda:.3f})\",\n",
    "        line=dict(color=\"#00FFFF\", width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train/Test split marker\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=train_end,\n",
    "    x1=train_end,\n",
    "    y0=0,\n",
    "    y1=1,\n",
    "    yref=\"paper\",\n",
    "    line=dict(color=\"red\", dash=\"dash\"),\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=train_end,\n",
    "    y=1,\n",
    "    yref=\"paper\",\n",
    "    text=\"Train/Test Split\",\n",
    "    showarrow=False,\n",
    "    textangle=-90,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"EWMA Forecast vs Realized Variance (Daily, Annualized)\",\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Date\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Variance\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nOut-of-Sample Performance Metrics:\")\n",
    "print(f\"RMSE (Variance units): {rmse:.6f}\")\n",
    "print(f\"MAE: {mae:.6f}\")\n",
    "print(f\"R-squared: {r2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ARCH(1) Forecast Function\n",
    "# -----------------------\n",
    "def arch1_forecast(returns, omega, alpha):\n",
    "    \"\"\"Generate ARCH(1) conditional variance forecasts (annualized).\"\"\"\n",
    "    var = np.zeros(len(returns))\n",
    "    var[0] = np.var(returns)  # unconditional variance init\n",
    "    for t in range(1, len(returns)):\n",
    "        var[t] = omega + alpha * returns.iloc[t - 1] ** 2\n",
    "    return var * 252\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Candidate grids\n",
    "# -----------------------\n",
    "window_candidates = [50, 100, 250, 500, 750]  # you can add more\n",
    "omega_grid = np.linspace(0.00001, 0.001, 10)\n",
    "alpha_grid = np.linspace(0.05, 0.95, 10)\n",
    "\n",
    "best_rmse = float(\"inf\")\n",
    "best_params = None\n",
    "best_forecast = None\n",
    "best_train_end = None\n",
    "\n",
    "# -----------------------\n",
    "# Grid Search over (window, omega, alpha)\n",
    "# -----------------------\n",
    "for window in window_candidates:\n",
    "    if window >= len(df):\n",
    "        continue  # skip if window > data\n",
    "\n",
    "    # define train/test split based on window size\n",
    "    train_data = df.iloc[:window]\n",
    "    test_data = df.iloc[window:]\n",
    "    train_end = train_data.index[-1]\n",
    "\n",
    "    for omega, alpha in product(omega_grid, alpha_grid):\n",
    "        # Forecast on training data\n",
    "        var_train = arch1_forecast(train_data[\"returns\"], omega, alpha)\n",
    "\n",
    "        # Out-of-sample forecast\n",
    "        var_all = pd.Series(index=df.index, dtype=float)\n",
    "        var_all.iloc[:window] = var_train\n",
    "        for t in range(window, len(df)):\n",
    "            var_all.iloc[t] = (omega + alpha * df[\"returns\"].iloc[t - 1] ** 2) * 252\n",
    "\n",
    "        # Compute OOS RMSE\n",
    "        oos_data = pd.DataFrame(\n",
    "            {\"realized\": realized_var[train_end:], \"arch_var\": var_all[train_end:]}\n",
    "        ).dropna()\n",
    "        rmse = np.sqrt(((oos_data[\"arch_var\"] - oos_data[\"realized\"]) ** 2).mean())\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = (window, omega, alpha)\n",
    "            best_forecast = var_all\n",
    "            best_train_end = train_end\n",
    "\n",
    "# -----------------------\n",
    "# Report Best Params\n",
    "# -----------------------\n",
    "print(\n",
    "    f\"Best parameters: window={best_params[0]}, omega={best_params[1]:.6f}, alpha={best_params[2]:.6f}\"\n",
    ")\n",
    "print(f\"Out-of-sample RMSE: {best_rmse:.6f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Regression (OOS only)\n",
    "# -----------------------\n",
    "aligned = pd.DataFrame({\"realized_var\": realized_var, \"arch_var\": best_forecast})\n",
    "\n",
    "oos_data = aligned[best_train_end:]\n",
    "X = sm.add_constant(oos_data[\"arch_var\"])\n",
    "y = oos_data[\"realized_var\"]\n",
    "model = sm.OLS(y, X).fit()\n",
    "r2 = model.rsquared\n",
    "\n",
    "print(f\"Out-of-sample R²: {r2:.2%}\")\n",
    "\n",
    "# -----------------------\n",
    "# Visualization\n",
    "# -----------------------\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=aligned.index,\n",
    "        y=aligned[\"realized_var\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Realized Variance\",\n",
    "        line=dict(color=\"#BC13FE\", width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=aligned.index,\n",
    "        y=aligned[\"arch_var\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"ARCH(1) Forecast (window={best_params[0]})\",\n",
    "        line=dict(color=\"#00FF7F\", width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add vertical line for train/test split\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=best_train_end,\n",
    "    x1=best_train_end,\n",
    "    y0=0,\n",
    "    y1=1,\n",
    "    yref=\"paper\",\n",
    "    line=dict(color=\"red\", dash=\"dash\"),\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=best_train_end,\n",
    "    y=1,\n",
    "    yref=\"paper\",\n",
    "    text=\"Train/Test Split\",\n",
    "    showarrow=False,\n",
    "    textangle=-90,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ARCH(1) Forecast vs Realized Variance (Annualized)\",\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Date\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Variance\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Why the ARCH(q) Model was Innovative?\n",
    "\n",
    "<u> **Conditional and Unconditional Expectation** </u>\n",
    "\n",
    "Given a filtration $\\mathcal{F}_{t-1}$, for an ARCH(q) process $\\epsilon_t = \\sigma_t z_t$ where $z_t \\sim i.i.d(0,1)$:\n",
    "\n",
    "$E[\\epsilon_t|\\mathcal{F}_{t-1}] = E[\\sigma_t z_t|\\mathcal{F}_{t-1}] = \\sigma_t E[z_t|\\mathcal{F}_{t-1}] = 0$\n",
    "\n",
    "$E[\\epsilon_t] = E[E[\\epsilon_t|\\mathcal{F}_{t-1}]] = 0$\n",
    "\n",
    "<u> **Conditional Variance** </u>\n",
    "\n",
    "The conditional variance follows directly from the ARCH(q) specification:\n",
    "\n",
    "$Var(\\epsilon_t|\\mathcal{F}_{t-1}) = \\sigma_t^2 = \\alpha_0 + \\sum_{i=1}^q \\alpha_i \\epsilon_{t-i}^2$\n",
    "\n",
    "<u> **Unconditional Variance** </u>\n",
    "\n",
    "The unconditional variance for an ARCH(q) process is:\n",
    "\n",
    "$Var(\\epsilon_t) = E[\\epsilon_t^2] = \\frac{\\alpha_0}{1-\\sum_{i=1}^q \\alpha_i}$\n",
    "\n",
    "This exists when $\\sum_{i=1}^q \\alpha_i < 1$\n",
    "\n",
    "The distribution itself is leptokurtic as it is a combination of a series of Gaussian innovations with different variances, big modelling innovation proven below!\n",
    "\n",
    "<u> **Kurtosis and Fat Tails** </u>\n",
    "\n",
    "For an ARCH(q) process, assuming $z_t$ is normally distributed:\n",
    "\n",
    "$Kurt(\\epsilon_t) = \\frac{E[\\epsilon_t^4]}{(E[\\epsilon_t^2])^2} = 3\\frac{1-(\\sum_{i=1}^q \\alpha_i)^2}{1-3\\sum_{i=1}^q \\alpha_i^2}$\n",
    "\n",
    "This exists when $3\\sum_{i=1}^q \\alpha_i^2 < 1$ and is greater than 3 (the normal distribution's kurtosis), indicating fat tails.\n",
    "\n",
    "\n",
    "###### ______________________________________________________________________________________________________________________________________\n",
    "\n",
    "**TL;DR : Given an ARCH(1) Process**\n",
    "- Zero conditional and unconditional mean\n",
    "- Conditional variance: $\\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2$ which is time-varying and depends on past shocks better capturing what we observed in data\n",
    "- Unconditional variance: $\\frac{\\alpha_0}{1 - \\alpha_1}$ if $\\alpha_1 < 1$ which is dictated by the model fit and parameters estimated \n",
    "- Kurtosis: Captures kurtosis in excess to a normal distribution assuming $3\\alpha_1^2 < 1$ which is what we observe in data\n",
    "- Volatility clustering is captured naturally! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### GARCH Models (Bollerslev 1986)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "##### *\"Generalized Autoregressive Conditionally Heteroskedastic Models\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "##### GARCH(p, q)\n",
    " \n",
    " $$y_t = \\mu + \\epsilon_t \\quad \\epsilon_t = \\sigma_t z_t \\quad z_t \\sim i.i.d(0, 1)$$\n",
    " \n",
    " - $y_t$ is the observed time series (e.g., returns at time t)\n",
    " - $\\mu$ is the constant mean of the process, typically close to zero\n",
    " - $\\epsilon_t$ is the error term (shock/innovation) at time t\n",
    " - $z_t$ is an i.i.d random variable with mean 0 and variance 1\n",
    " \n",
    " $$\\sigma_t^2 = \\alpha_0 + \\sum_{i=0}^q \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=0}^p \\beta_j \\sigma_{t-j}^2$$\n",
    " \n",
    " - $\\sigma_t^2$ is the conditional variance or volatility at time t\n",
    " - $\\alpha_0$ is the constant term (must be positive)\n",
    " - $\\alpha_i$ are coefficients on lagged squared residuals (must be nonnegative)\n",
    " - $\\beta_1$ are coefficients on lagged conditional variances (must be nonnegative)\n",
    " \n",
    " The most widely used case is a GARCH(1, 1)\n",
    " \n",
    " $$\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2$$\n",
    "\n",
    "##### Why use GARCH over ARCH?\n",
    "\n",
    "GARCH is a more parsimonious ARCH model, in fact, an ARCH($\\infty$) is equal to a GARCH(1, 1)\n",
    "\n",
    " Consider an ARCH(∞) process:\n",
    " $$\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\alpha_2 \\epsilon_{t-2}^2 + ...$$\n",
    " \n",
    " We can rewrite this as:\n",
    " $$\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\alpha_2 \\epsilon_{t-2}^2 + ...$$\n",
    " $$\\sigma_{t-1}^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-2}^2 + \\alpha_2 \\epsilon_{t-3}^2 + ...$$\n",
    " \n",
    " Multiply the second equation by β:\n",
    " $$\\beta\\sigma_{t-1}^2 = \\beta\\alpha_0 + \\beta\\alpha_1 \\epsilon_{t-2}^2 + \\beta\\alpha_2 \\epsilon_{t-3}^2 + ...$$\n",
    " \n",
    " Subtracting this from the first equation:\n",
    " $$\\sigma_t^2 - \\beta\\sigma_{t-1}^2 = \\alpha_0(1-\\beta) + \\alpha_1 \\epsilon_{t-1}^2 + (\\alpha_2-\\beta\\alpha_1)\\epsilon_{t-2}^2 + ...$$\n",
    " \n",
    " Rearranging:\n",
    " $$\\sigma_t^2 = \\alpha_0(1-\\beta) + \\alpha_1 \\epsilon_{t-1}^2 + \\beta\\sigma_{t-1}^2$$\n",
    " \n",
    " This is exactly the form of a GARCH(1,1) process with parameters:\n",
    " - $\\omega = \\alpha_0(1-\\beta)$\n",
    " - $\\alpha = \\alpha_1$\n",
    " - $\\beta = \\beta$\n",
    " \n",
    " Therefore, any ARCH(∞) process can be represented as a more parsimonious GARCH(1,1) process.\n",
    "\n",
    "We can capture the same dynamics in the infinite ARCH process as a simple GARCH(1,1), wild!\n",
    "\n",
    "##### Example: GARCH Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARCH(1,1) Forecast Function\n",
    "# -----------------------\n",
    "def garch11_forecast(returns, omega, alpha, beta):\n",
    "    \"\"\"Generate GARCH(1,1) conditional variance forecasts (annualized).\"\"\"\n",
    "    var = np.zeros(len(returns))\n",
    "    var[0] = np.var(returns)  # unconditional variance init\n",
    "    for t in range(1, len(returns)):\n",
    "        var[t] = omega + alpha * returns.iloc[t - 1] ** 2 + beta * var[t - 1]\n",
    "    return var * 252\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Candidate grids\n",
    "# -----------------------\n",
    "window_candidates = [50, 100, 250, 500, 750]\n",
    "omega_grid = np.linspace(0.00001, 0.001, 5)\n",
    "alpha_grid = np.linspace(0.05, 0.95, 5)\n",
    "beta_grid = np.linspace(0.05, 0.95, 5)\n",
    "\n",
    "best_rmse = float(\"inf\")\n",
    "best_params = None\n",
    "best_forecast = None\n",
    "best_train_end = None\n",
    "\n",
    "# -----------------------\n",
    "# Grid Search over (window, omega, alpha, beta)\n",
    "# -----------------------\n",
    "for window in window_candidates:\n",
    "    if window >= len(df):\n",
    "        continue\n",
    "\n",
    "    train_data = df.iloc[:window]\n",
    "    test_data = df.iloc[window:]\n",
    "    train_end = train_data.index[-1]\n",
    "\n",
    "    for omega, alpha, beta in product(omega_grid, alpha_grid, beta_grid):\n",
    "        if alpha + beta >= 1:\n",
    "            continue  # ensure stationarity\n",
    "\n",
    "        # Forecast on training data\n",
    "        var_train = garch11_forecast(train_data[\"returns\"], omega, alpha, beta)\n",
    "\n",
    "        # Out-of-sample forecast\n",
    "        var_all = pd.Series(index=df.index, dtype=float)\n",
    "        var_all.iloc[:window] = var_train\n",
    "        for t in range(window, len(df)):\n",
    "            var_all.iloc[t] = (\n",
    "                omega\n",
    "                + alpha * df[\"returns\"].iloc[t - 1] ** 2\n",
    "                + beta * var_all.iloc[t - 1] / 252\n",
    "            ) * 252\n",
    "\n",
    "        # Compute OOS RMSE\n",
    "        oos_data = pd.DataFrame(\n",
    "            {\"realized\": realized_var[train_end:], \"garch_var\": var_all[train_end:]}\n",
    "        ).dropna()\n",
    "        rmse = np.sqrt(((oos_data[\"garch_var\"] - oos_data[\"realized\"]) ** 2).mean())\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = (window, omega, alpha, beta)\n",
    "            best_forecast = var_all\n",
    "            best_train_end = train_end\n",
    "\n",
    "# -----------------------\n",
    "# Report Best Params\n",
    "# -----------------------\n",
    "print(\n",
    "    f\"Best parameters: window={best_params[0]}, \"\n",
    "    f\"omega={best_params[1]:.6f}, alpha={best_params[2]:.6f}, beta={best_params[3]:.6f}\"\n",
    ")\n",
    "print(f\"Out-of-sample RMSE: {best_rmse:.6f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Regression (OOS only)\n",
    "# -----------------------\n",
    "aligned = pd.DataFrame({\"realized_var\": realized_var, \"garch_var\": best_forecast})\n",
    "\n",
    "oos_data = aligned[best_train_end:]\n",
    "X = sm.add_constant(oos_data[\"garch_var\"])\n",
    "y = oos_data[\"realized_var\"]\n",
    "model = sm.OLS(y, X).fit()\n",
    "r2 = model.rsquared\n",
    "\n",
    "print(f\"Out-of-sample R²: {r2:.2%}\")\n",
    "\n",
    "# -----------------------\n",
    "# Visualization\n",
    "# -----------------------\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=aligned.index,\n",
    "        y=aligned[\"realized_var\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Realized Variance\",\n",
    "        line=dict(color=\"#BC13FE\", width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=aligned.index,\n",
    "        y=aligned[\"garch_var\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"GARCH(1,1) Forecast (window={best_params[0]})\",\n",
    "        line=dict(color=\"#00FF7F\", width=1.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=best_train_end,\n",
    "    x1=best_train_end,\n",
    "    y0=0,\n",
    "    y1=1,\n",
    "    yref=\"paper\",\n",
    "    line=dict(color=\"red\", dash=\"dash\"),\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=best_train_end,\n",
    "    y=1,\n",
    "    yref=\"paper\",\n",
    "    text=\"Train/Test Split\",\n",
    "    showarrow=False,\n",
    "    textangle=-90,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"GARCH(1,1) Forecast vs Realized Variance (Annualized)\",\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Date\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Variance\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________\n",
    "\n",
    "**TL;DR: GARCH(1,1) Process Compared to ARCH(∞)**\n",
    "\n",
    "Given a GARCH(1,1) Process:\n",
    "- Zero conditional and unconditional mean\n",
    "- Conditional variance: $\\sigma_t^2 = \\omega + \\alpha\\epsilon_{t-1}^2 + \\beta\\sigma_{t-1}^2$\n",
    "- Can be rewritten as an ARCH(∞) process by recursive substitution:\n",
    "  $\\sigma_t^2 = \\frac{\\omega}{1-\\beta} + \\alpha\\sum_{i=1}^{\\infty}\\beta^{i-1}\\epsilon_{t-i}^2$\n",
    "- Unconditional variance: $\\frac{\\omega}{1-\\alpha-\\beta}$ if $\\alpha + \\beta < 1$\n",
    "- More parsimonious than ARCH with similar benefits:\n",
    "  - Captures volatility clustering\n",
    "  - Models excess kurtosis\n",
    "  - Time-varying conditional variance\n",
    "- Advantage over ARCH: Requires fewer parameters while capturing long-memory dependence through the $\\beta$ term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### Applications of ARCH/GARCH Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "##### Portfolio Risk Management\n",
    "\n",
    " Value at Risk (VaR) is a critical risk measure in portfolio management, defined as:\n",
    " \n",
    " $$VaR_{\\alpha} = -\\sigma \\cdot z_{\\alpha}$$\n",
    " \n",
    " where $z_{\\alpha}$ is the $\\alpha$-quantile of the standard normal distribution and $\\sigma$ is the volatility.\n",
    " \n",
    " The traditional parametric VaR approach assumes homoskedasticity (constant variance), using:\n",
    " \n",
    " $$\\sigma_{global} = \\sqrt{\\frac{1}{T-1}\\sum_{t=1}^T (r_t - \\bar{r})^2}$$\n",
    " \n",
    " However, this fails to capture the dynamic nature of volatility in financial markets. GARCH models provide superior VaR estimates by modeling time-varying volatility:\n",
    " \n",
    " $$\\sigma_t^2 = \\omega + \\alpha\\epsilon_{t-1}^2 + \\beta\\sigma_{t-1}^2$$\n",
    " \n",
    " This allows the VaR estimate to adapt to changing market conditions, providing more accurate risk forecasts during both calm and volatile periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Parameters\n",
    "# -----------------------\n",
    "alpha = 0.05  # 5% VaR\n",
    "z_alpha = norm.ppf(alpha)  # ≈ -1.645\n",
    "\n",
    "# -----------------------\n",
    "# Naïve (parametric) VaR\n",
    "# -----------------------\n",
    "# Use unconditional volatility (std of returns)\n",
    "sigma_naive = df[\"returns\"].std()\n",
    "sigma_naive_daily = sigma_naive / np.sqrt(252)  # convert annual to daily if needed\n",
    "\n",
    "VaR_naive = z_alpha * sigma_naive_daily\n",
    "\n",
    "# -----------------------\n",
    "# GARCH(1,1) VaR\n",
    "# -----------------------\n",
    "sigma_daily = np.sqrt(best_forecast / 252)\n",
    "VaR_garch = z_alpha * sigma_daily\n",
    "\n",
    "# -----------------------\n",
    "# Create DataFrame\n",
    "# -----------------------\n",
    "var_df = pd.DataFrame(\n",
    "    {\"returns\": df[\"returns\"], \"VaR_Naive\": VaR_naive, \"VaR_GARCH\": VaR_garch}\n",
    ").dropna()\n",
    "\n",
    "# -----------------------\n",
    "# Exceedances\n",
    "# -----------------------\n",
    "exceed_naive = var_df[var_df[\"returns\"] < var_df[\"VaR_Naive\"]]\n",
    "exceed_garch = var_df[var_df[\"returns\"] < var_df[\"VaR_GARCH\"]]\n",
    "\n",
    "prop_exceed_naive = len(exceed_naive) / len(var_df)\n",
    "prop_exceed_garch = len(exceed_garch) / len(var_df)\n",
    "\n",
    "print(f\"Proportion of exceedances (Naïve): {prop_exceed_naive:.2%}\")\n",
    "print(f\"Proportion of exceedances (GARCH): {prop_exceed_garch:.2%}\")\n",
    "\n",
    "# -----------------------\n",
    "# Visualization\n",
    "# -----------------------\n",
    "fig = go.Figure()\n",
    "\n",
    "# Portfolio returns\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=var_df.index,\n",
    "        y=var_df[\"returns\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Portfolio Returns\",\n",
    "        line=dict(color=\"white\", width=1),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Naïve VaR\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=var_df.index,\n",
    "        y=var_df[\"VaR_Naive\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"5% Naïve VaR (Exceed: {prop_exceed_naive:.2%})\",\n",
    "        line=dict(color=\"orange\", width=2, dash=\"dot\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# GARCH VaR\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=var_df.index,\n",
    "        y=var_df[\"VaR_GARCH\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"5% GARCH(1,1) VaR (Exceed: {prop_exceed_garch:.2%})\",\n",
    "        line=dict(color=\"#FF3131\", width=2, dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Highlight exceedances (Naïve)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=exceed_naive.index,\n",
    "        y=exceed_naive[\"returns\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"Naïve Exceedances\",\n",
    "        marker=dict(color=\"orange\", size=7, symbol=\"x\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Highlight exceedances (GARCH)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=exceed_garch.index,\n",
    "        y=exceed_garch[\"returns\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"GARCH Exceedances\",\n",
    "        marker=dict(color=\"red\", size=7, symbol=\"cross\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=\"1-Day 5% VaR: Naïve vs GARCH(1,1)\",\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Date\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"rgba(128,128,128,0.2)\",\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor=\"rgba(128,128,128,0.5)\",\n",
    "    title_text=\"Return / VaR\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### Closing Thoughts and Future Topics\n",
    "\n",
    "TL;DW Executive Summary\n",
    "- Volatility is an unobservable measure of variability in the return space\n",
    "- We can proxy for volatility in a backward looking sense (historic or realized volatility) or in a forward looking sense (implied volatility)\n",
    "- There are many stylized facts about volatility including the leverage effect, volatility clustering, excess kurtosis (fat tails, leptokurtic return distributions)\n",
    "- Naive parametric models fail to capture these dynamics and severly underestimate tail risk - a big problem!\n",
    "- Engle proposed ARCH, an autoregressive conditionally heteroskedastic model capable of modeling these dynamics improving forecasts!\n",
    "- Bollerslev proposed a generalized ARCH model (GARCH) which is an infinite order ARCH model, thus a more parsimonious version\n",
    "- GARCH can capture richer dynamics with fewer lags, impressive!\n",
    "- These volatility models outperform other models that do not account for dynamics especially in the context of risk modelling as we saw in our VaR example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aichf-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
